# ğŸ“¦ Product Data Explorer â€“ Full Stack Application

A full-stack product exploration platform built using **Next.js**, **NestJS**, **Prisma**, **PostgreSQL**, and a custom **web scraper** powered by **Crawlee + Playwright**.

This project demonstrates real-world full-stack development, including data scraping, API design, database modeling, caching, pagination, and a modern frontend architecture.

---

## ğŸš€ Features

### ğŸ”¹ Frontend (Next.js)
- Navigation menu powered by backend APIs
- Category-wise product listing
- Product detail page with description & reviews
- Pagination for large product lists
- View History (recently viewed products)
- Data caching & refetching using **React Query**
- Responsive UI with reusable components

### ğŸ”¹ Backend (NestJS)
- REST APIs for navigation, categories, products, and product details
- Prisma ORM with PostgreSQL
- Modular architecture (Navigation, Category, Product, Scrape, History)
- Background scrape job handling
- Input validation using DTOs & pipes

### ğŸ”¹ Scraper (Crawlee + Playwright)
- Scrapes real product navigation & data
- Normalizes titles, slugs, and URLs
- Sends scraped data directly to backend APIs
- Configurable delay for polite scraping

---

## ğŸ§± Tech Stack

| Layer        | Technology |
|-------------|------------|
| Frontend     | Next.js (App Router), React Query, Tailwind CSS |
| Backend      | NestJS, Prisma ORM |
| Database     | PostgreSQL |
| Scraper      | Crawlee, Playwright |
| Language     | TypeScript |
| Tooling      | Axios, Zod, ESLint |

---

## ğŸ“‚ Project Structure

product-data-explorer/
â”‚
â”œâ”€â”€ frontend/ # Next.js application
â”œâ”€â”€ backend/ # NestJS API + Prisma
â”œâ”€â”€ scraper/ # Crawlee + Playwright scraper
â””â”€â”€ README.md

yaml
Copy code

---

## âš™ï¸ Environment Setup

### ğŸ”¹ Backend (`backend/.env`)
```env
DATABASE_URL=postgresql://user:password@localhost:5432/product_explorer
PORT=4000
ğŸ”¹ Frontend (frontend/.env)
env
Copy code
NEXT_PUBLIC_API_URL=http://localhost:4000
ğŸ”¹ Scraper (scraper/.env)
env
Copy code
BASE_URL=https://www.worldofbooks.com
SCRAPE_DELAY_MS=200
â–¶ï¸ Running the Project Locally
1ï¸âƒ£ Backend
bash
Copy code
cd backend
npm install
npx prisma migrate dev
npx prisma generate
npm run start:dev
Backend runs on: http://localhost:4000

2ï¸âƒ£ Frontend
bash
Copy code
cd frontend
npm install
npm run dev
Frontend runs on: http://localhost:3000

3ï¸âƒ£ Scraper
bash
Copy code
cd scraper
npm install
npx playwright install chromium
npm run start
This will scrape navigation data and send it to the backend.

ğŸ”— API Endpoints (Sample)
Method	Endpoint	Description
GET	/navigation	Fetch navigation menu
GET	/categories/:navigationSlug	Category list
GET	/products	Paginated products
GET	/products/:sourceId	Product detail
POST	/scrape/navigation	Save scraped navigation
POST	/history	Store view history

ğŸš§ Deployment Status
Live deployment could not be completed due to environment-specific build and configuration issues on the hosting platform.

However:

âœ… Frontend runs correctly in local development

âœ… Backend APIs are fully functional

âœ… Database schema & relations are complete

âœ… Scraper successfully fetches and sends data

Clear setup instructions are provided to run the project locally without issues.

ğŸ¯ Learning Outcomes
Full-stack architecture design

Prisma relational schema modeling

Real-world web scraping

Pagination & caching strategies

Clean modular backend structure

Frontend performance optimization with React Query

ğŸ‘©â€ğŸ’» Author
Saloni Saini
Aspiring Full Stack Developer
GitHub: https://github.com/SaloniSsSaini
